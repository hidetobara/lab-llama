FROM nvidia/cuda:12.4.1-cudnn-runtime-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive PIP_PREFER_BINARY=1
EXPOSE 11434

RUN apt -y update && apt -y install git vim less python3-pip wget curl

WORKDIR /workdir
RUN curl -fsSL https://ollama.com/install.sh | sh
RUN pip3 install ollama

# NEED ollama serve, pull llama3
